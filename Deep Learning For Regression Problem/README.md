### Deep Learning Model For Regression Problem 

In building your deep learning model, you likely designed a network architecture suitable for regression. You may have used a combination of densely connected layers or convolutional layers, depending on the nature of your data. These layers allow the model to learn complex patterns and relationships from the input features, enabling accurate predictions of continuous values.

During training, you fed your model with a labeled dataset, consisting of input features and corresponding target values. You employed a loss function appropriate for regression, such as mean squared error (MSE) or mean absolute error (MAE), which measure the difference between predicted and true values. By iteratively optimizing the model's weights using optimization algorithms like stochastic gradient descent (SGD) or Adam, you successfully minimized the loss function and achieved a low loss value.

A low loss indicates that your model has effectively learned the underlying patterns and dependencies in the data, enabling it to make accurate predictions. This achievement demonstrates the efficacy of deep learning in capturing complex relationships and uncovering hidden patterns in regression problems.

In addition to achieving low loss, it is essential to evaluate your model's performance on unseen data to ensure its generalization ability. You can utilize metrics such as mean absolute error (MAE), mean squared error (MSE), or R-squared (R^2) to quantify the model's predictive accuracy and assess its performance on new instances.

### Dataset Link
### https://www.kaggle.com/datasets/devzohaib/tvmarketingcsv
